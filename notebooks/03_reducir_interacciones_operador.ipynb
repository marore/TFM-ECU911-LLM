{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0e450a",
   "metadata": {},
   "source": [
    "En este notebook que es parte de v5-CLASS-bert_ft.ipynb se va a realizar la reducción de las opciones de las interacciones del operador con un LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4143d21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/bert_ft_marcos/vllm_experiments/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cb1c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3847 entries, 0 to 5049\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  3847 non-null   object\n",
      " 1   ACTOR             3847 non-null   object\n",
      " 2   DIALOG_ACT        3847 non-null   object\n",
      " 3   SUBACT            3847 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 150.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"processed_llm_output_anonimized_clean.xlsx\",\n",
    "                   usecols=[\"ACTOR\", \"DIALOG_ACT\", \"SUBACT\", \"ATA_TEXTO_TAGGED\"])\n",
    "# eliminar interacciones duplicadas\n",
    "df = df.drop_duplicates(subset=[\"ATA_TEXTO_TAGGED\"], keep=\"first\")\n",
    "# antes de eliminar duplicados había 5052 registros\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aad5e89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1778, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ver el número de interacciones de los operadores\n",
    "df_operadores = df[df[\"ACTOR\"] == \"Operador\"].copy()\n",
    "df_operadores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b54a8294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "DIALOG_ACT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c07194ac-4501-4379-8a3c-d1ce868fbd3b",
       "rows": [
        [
         "Pregunta",
         "1446"
        ],
        [
         "Rutina",
         "196"
        ],
        [
         "Descripción",
         "93"
        ],
        [
         "Orden",
         "38"
        ],
        [
         "Ruido",
         "5"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "DIALOG_ACT\n",
       "Pregunta       1446\n",
       "Rutina          196\n",
       "Descripción      93\n",
       "Orden            38\n",
       "Ruido             5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de las 3847 interacciones, 1778 son de los operadores\n",
    "# ahora revisar por acto de diáologo\n",
    "df_operadores[\"DIALOG_ACT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53a66f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "SUBACT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "423bcd6e-18cb-46dd-ae50-46a84d497f44",
       "rows": [
        [
         "localización",
         "641"
        ],
        [
         "otro",
         "312"
        ],
        [
         "confirmación",
         "219"
        ],
        [
         "contacto",
         "179"
        ],
        [
         "rutina_operador",
         "154"
        ],
        [
         "tipo_incidente",
         "140"
        ],
        [
         "heridos",
         "58"
        ],
        [
         "cortesía",
         "36"
        ],
        [
         "permanecer_línea",
         "23"
        ],
        [
         "evolución",
         "5"
        ],
        [
         "ruido",
         "5"
        ],
        [
         "seguir_instrucciones",
         "4"
        ],
        [
         "acción_seguridad",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 13
       }
      },
      "text/plain": [
       "SUBACT\n",
       "localización            641\n",
       "otro                    312\n",
       "confirmación            219\n",
       "contacto                179\n",
       "rutina_operador         154\n",
       "tipo_incidente          140\n",
       "heridos                  58\n",
       "cortesía                 36\n",
       "permanecer_línea         23\n",
       "evolución                 5\n",
       "ruido                     5\n",
       "seguir_instrucciones      4\n",
       "acción_seguridad          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ahora revisar por subacto de dialogo\n",
    "df_operadores[\"SUBACT\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c246c86",
   "metadata": {},
   "source": [
    "Lo que se me ocurre es ir reduciendo de poco a poco, ir seleccionando primero cada uno de los actos de diálogo macros con cada uno de sus subactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3a2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estos son los actos de diálogo:\n",
    "\n",
    "# Pregunta\n",
    "# Rutina\n",
    "# Descripción\n",
    "# Orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fcc1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# este es el cliente del gpt oss que está corriendo como\n",
    "# servicio en el hpc\n",
    "from openai import OpenAI\n",
    "\n",
    "system_prompt = \"\"\"You are a linguistic analyst specialized in emergency call transcripts.\n",
    "You must follow instructions precisely and output only the requested format.\n",
    "Reasoning: high\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:8010/v1\", api_key=\"EMPTY\")\n",
    "\n",
    "def get_llm_answer(user_prompt):\n",
    "    \n",
    "    result = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt  \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return (result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb356a",
   "metadata": {},
   "source": [
    "# Pregunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86526a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "SUBACT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "46636dc0-67b8-4da5-b3b9-83bc0f8134f3",
       "rows": [
        [
         "localización",
         "623"
        ],
        [
         "otro",
         "234"
        ],
        [
         "confirmación",
         "219"
        ],
        [
         "contacto",
         "179"
        ],
        [
         "tipo_incidente",
         "135"
        ],
        [
         "heridos",
         "56"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 6
       }
      },
      "text/plain": [
       "SUBACT\n",
       "localización      623\n",
       "otro              234\n",
       "confirmación      219\n",
       "contacto          179\n",
       "tipo_incidente    135\n",
       "heridos            56\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para Pregunta, estos son los subactos\n",
    "df_operadores_pregunta = df_operadores[df_operadores[\"DIALOG_ACT\"] == \"Pregunta\"].copy()\n",
    "df_operadores_pregunta[\"SUBACT\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf921cd9",
   "metadata": {},
   "source": [
    "## Localización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29a1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De Pregunta, reducir primero localización\n",
    "df_operadores_pregunta_localizacion = df_operadores_pregunta[df_operadores_pregunta[\"SUBACT\"] == \"localización\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d35b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "loc_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Question\n",
    "- SUBACT: Localization\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE QUESTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that request the SAME information.\n",
    "- Do NOT merge questions that request DIFFERENT information.\n",
    "- Write natural, neutral questions an operator would ask.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Canonical questions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_questions\": [\n",
    "    \"Pregunta canónica 1?\",\n",
    "    \"Pregunta canónica 2?\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a98fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 623 interacciones o preguntas de localización\n",
    "# se enviarán lotes de 50 en 50\n",
    "# luego cuando se hayan reducido, se unificarán las oraciones generales\n",
    "# y se volverá a solicitar al LLM que las reduzca una última vez\n",
    "# así nos aseguramos de que el LLM haya observado todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d148960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing location questions: 100%|████████████████████████████████████████████████████████| 13/13 [02:58<00:00, 13.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "slice_size = 50\n",
    "num_rows = len(df_operadores_pregunta_localizacion)\n",
    "\n",
    "for i in tqdm(range(0, num_rows, slice_size), desc=\"Processing location questions\"):\n",
    "    sliced_df = df_operadores_pregunta_localizacion.iloc[i:i + slice_size]\n",
    "    utterances = sliced_df[\"ATA_TEXTO_TAGGED\"].tolist()\n",
    "\n",
    "    user_prompt = loc_prompt + str(utterances)\n",
    "\n",
    "    response = get_llm_answer(user_prompt)\n",
    "\n",
    "    parsed_response = json_repair.repair_json(\n",
    "        response,\n",
    "        return_objects=True,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    "    \n",
    "    temp_df = pd.DataFrame({\n",
    "        \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "    })\n",
    "    \n",
    "    temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "    temp_df_name = (\n",
    "        f\"reduccion_interacciones_operador/\"\n",
    "        f\"reduccion_pregunta/\"\n",
    "        f\"reduccion_localizacion/v1/{i}_{i+len(sliced_df)-1}.csv\"\n",
    "    )\n",
    "\n",
    "    temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez procesados todas las 623 interacciones del operador de:\n",
    "# PREGUNTA / LOCALIZACIÓN\n",
    "# como se enviaron en lotes de 50 en 50 y fueron guardados en csvs\n",
    "# ahora se van a concantenar los 13 csvs en uno solo y una última vez\n",
    "# se solicitará al LLM con el mismo prompt que reduzca las interacciones\n",
    "# esto nos dará las preguntas canónicas o base que ha hecho un operador\n",
    "# de la categoría pregunta/localizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360565ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  52 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 544.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "dir = \"reduccion_interacciones_operador/reduccion_pregunta/reduccion_localizacion/v1\"\n",
    "\n",
    "all_csv = glob.glob(os.path.join(dir, \"*.csv\"))\n",
    "concat_df = pd.concat(map(pd.read_csv, all_csv), ignore_index=True)\n",
    "print(concat_df.info())\n",
    "concat_df.to_csv(dir+\"/concat_all_dfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "655f8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como vemos, de todas las 623 interacciones de obtuvieron 52 preguntas canónicas\n",
    "# ahora se van a enviar las 52 preguntas al LLM para obtener las base, ya que el LLM\n",
    "# solo veía lotes de 50 entonces puede que existan preguntas muy parecidas\n",
    "import pandas as pd\n",
    "\n",
    "utterances = str(concat_df[\"canonical_questions\"].tolist())\n",
    "user_prompt = loc_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_localizacion/v1/final_pregunta_localizacion.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cffb53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  8 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ce9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 8 preguntas canónicas de localizalización\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_localizacion/v1/final_pregunta_localizacion.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d102dde",
   "metadata": {},
   "source": [
    "## Otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82c36c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 234 entries, 0 to 5046\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  234 non-null    object\n",
      " 1   ACTOR             234 non-null    object\n",
      " 2   DIALOG_ACT        234 non-null    object\n",
      " 3   SUBACT            234 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 9.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# De Pregunta, reducir ahora Otro\n",
    "df_operadores_pregunta_otro = df_operadores_pregunta[df_operadores_pregunta[\"SUBACT\"] == \"otro\"]\n",
    "df_operadores_pregunta_otro.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52bf422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "other_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Question\n",
    "- SUBACT: Other\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE QUESTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that request the SAME information.\n",
    "- Do NOT merge questions that request DIFFERENT information.\n",
    "- Write natural, neutral questions an operator would ask.\n",
    "- Canonical questions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_questions\": [\n",
    "    \"Pregunta canónica 1?\",\n",
    "    \"Pregunta canónica 2?\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c40654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 234 interacciones o preguntas de otro\n",
    "# se enviarán lotes de 50 en 50\n",
    "# luego cuando se hayan reducido, se unificarán las oraciones generales\n",
    "# y se volverá a solicitar al LLM que las reduzca una última vez\n",
    "# así nos aseguramos de que el LLM haya observado todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83836cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing other questions: 100%|█████████████████████████████████████████████████████████████| 5/5 [02:12<00:00, 26.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "slice_size = 50\n",
    "num_rows = len(df_operadores_pregunta_otro)\n",
    "\n",
    "for i in tqdm(range(0, num_rows, slice_size), desc=\"Processing other questions\"):\n",
    "    sliced_df = df_operadores_pregunta_otro.iloc[i:i + slice_size]\n",
    "    utterances = sliced_df[\"ATA_TEXTO_TAGGED\"].tolist()\n",
    "\n",
    "    user_prompt = other_prompt + str(utterances)\n",
    "\n",
    "    response = get_llm_answer(user_prompt)\n",
    "\n",
    "    parsed_response = json_repair.repair_json(\n",
    "        response,\n",
    "        return_objects=True,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    "    \n",
    "    temp_df = pd.DataFrame({\n",
    "        \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "    })\n",
    "    \n",
    "    temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "    temp_df_name = (\n",
    "        f\"reduccion_interacciones_operador/\"\n",
    "        f\"reduccion_pregunta/\"\n",
    "        f\"reduccion_otro/v1/{i}_{i+len(sliced_df)-1}.csv\"\n",
    "    )\n",
    "\n",
    "    temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "767c3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez procesados todas las 234 interacciones del operador de:\n",
    "# PREGUNTA / OTRO\n",
    "# como se enviaron en lotes de 50 en 50 y fueron guardados en csvs\n",
    "# ahora se van a concantenar los 5 csvs en uno solo y una última vez\n",
    "# se solicitará al LLM con el mismo prompt que reduzca las interacciones\n",
    "# esto nos dará las preguntas canónicas o base que ha hecho un operador\n",
    "# de la categoría pregunta/otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b8bb915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66 entries, 0 to 65\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  66 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 656.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "dir = \"reduccion_interacciones_operador/reduccion_pregunta/reduccion_otro/v1\"\n",
    "all_csv = glob.glob(os.path.join(dir, \"*.csv\"))\n",
    "concat_df = pd.concat(map(pd.read_csv, all_csv), ignore_index=True)\n",
    "print(concat_df.info())\n",
    "concat_df.to_csv(dir+\"/concat_all_dfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8a5a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como vemos, de todas las 234 interacciones de obtuvieron 66 preguntas canónicas\n",
    "# ahora se van a enviar las 66 preguntas al LLM para obtener las base, ya que el LLM\n",
    "# solo veía lotes de 50 entonces puede que existan preguntas muy parecidas\n",
    "import pandas as pd\n",
    "\n",
    "utterances = str(concat_df[\"canonical_questions\"].tolist())\n",
    "user_prompt = other_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_otro/v1/final_pregunta_otro.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb35dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29 entries, 0 to 28\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  29 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 360.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb55d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 29 preguntas canónicas de otro\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_otro/v1/final_pregunta_otro.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77524351",
   "metadata": {},
   "source": [
    "## Confirmación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f776012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 219 entries, 72 to 4989\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  219 non-null    object\n",
      " 1   ACTOR             219 non-null    object\n",
      " 2   DIALOG_ACT        219 non-null    object\n",
      " 3   SUBACT            219 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 8.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# De Pregunta, reducir ahora Otro\n",
    "df_operadores_pregunta_confirmacion = df_operadores_pregunta[df_operadores_pregunta[\"SUBACT\"] == \"confirmación\"]\n",
    "df_operadores_pregunta_confirmacion.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc6c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "conf_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Question\n",
    "- SUBACT: Confirmation\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE QUESTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that request the SAME information.\n",
    "- Do NOT merge questions that request DIFFERENT information.\n",
    "- Write natural, neutral questions an operator would ask.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Canonical questions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_questions\": [\n",
    "    \"Pregunta canónica 1?\",\n",
    "    \"Pregunta canónica 2?\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5968525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 219 interacciones o preguntas de confirmación\n",
    "# se enviarán lotes de 50 en 50\n",
    "# luego cuando se hayan reducido, se unificarán las oraciones generales\n",
    "# y se volverá a solicitar al LLM que las reduzca una última vez\n",
    "# así nos aseguramos de que el LLM haya observado todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "594135c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing confirmation questions:   0%|                                                              | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing confirmation questions: 100%|██████████████████████████████████████████████████████| 5/5 [01:59<00:00, 23.82s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "slice_size = 50\n",
    "num_rows = len(df_operadores_pregunta_confirmacion)\n",
    "\n",
    "for i in tqdm(range(0, num_rows, slice_size), desc=\"Processing confirmation questions\"):\n",
    "    sliced_df = df_operadores_pregunta_confirmacion.iloc[i:i + slice_size]\n",
    "    utterances = sliced_df[\"ATA_TEXTO_TAGGED\"].tolist()\n",
    "\n",
    "    user_prompt = conf_prompt + str(utterances)\n",
    "\n",
    "    response = get_llm_answer(user_prompt)\n",
    "\n",
    "    parsed_response = json_repair.repair_json(\n",
    "        response,\n",
    "        return_objects=True,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    "    \n",
    "    temp_df = pd.DataFrame({\n",
    "        \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "    })\n",
    "    \n",
    "    temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "    temp_df_name = (\n",
    "        f\"reduccion_interacciones_operador/\"\n",
    "        f\"reduccion_pregunta/\"\n",
    "        f\"reduccion_confirmacion/v1/{i}_{i+len(sliced_df)-1}.csv\"\n",
    "    )\n",
    "\n",
    "    temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6c96cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez procesados todas las 219 interacciones del operador de:\n",
    "# PREGUNTA / CONFIRMACIÓN\n",
    "# como se enviaron en lotes de 50 en 50 y fueron guardados en csvs\n",
    "# ahora se van a concantenar los 5 csvs en uno solo y una última vez\n",
    "# se solicitará al LLM con el mismo prompt que reduzca las interacciones\n",
    "# esto nos dará las preguntas canónicas o base que ha hecho un operador\n",
    "# de la categoría pregunta/confirmación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062a973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  25 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 328.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "dir = \"reduccion_interacciones_operador/reduccion_pregunta/reduccion_confirmacion/v1\"\n",
    "all_csv = glob.glob(os.path.join(dir, \"*.csv\"))\n",
    "concat_df = pd.concat(map(pd.read_csv, all_csv), ignore_index=True)\n",
    "print(concat_df.info())\n",
    "concat_df.to_csv(dir+\"/concat_all_dfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7b31b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como vemos, de todas las 234 interacciones de obtuvieron 25 preguntas canónicas\n",
    "# ahora se van a enviar las 25 preguntas al LLM para obtener las base, ya que el LLM\n",
    "# solo veía lotes de 50 entonces puede que existan preguntas muy parecidas\n",
    "import pandas as pd\n",
    "\n",
    "utterances = str(concat_df[\"canonical_questions\"].tolist())\n",
    "user_prompt = conf_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_confirmacion/v1/final_pregunta_confirmacion.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "245990ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22 entries, 0 to 21\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  22 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 304.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de692930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 22 preguntas canónicas de confirmación\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_confirmacion/v1/final_pregunta_confirmacion.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180a189",
   "metadata": {},
   "source": [
    "## Contacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de1a7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 179 entries, 24 to 5048\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  179 non-null    object\n",
      " 1   ACTOR             179 non-null    object\n",
      " 2   DIALOG_ACT        179 non-null    object\n",
      " 3   SUBACT            179 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 7.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# De Pregunta, reducir ahora Contacto\n",
    "df_operadores_pregunta_contacto = df_operadores_pregunta[df_operadores_pregunta[\"SUBACT\"] == \"contacto\"]\n",
    "df_operadores_pregunta_contacto.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625dcaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "contact_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Question\n",
    "- SUBACT: Contact\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE QUESTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that request the SAME information.\n",
    "- Do NOT merge questions that request DIFFERENT information.\n",
    "- Write natural, neutral questions an operator would ask.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Canonical questions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_questions\": [\n",
    "    \"Pregunta canónica 1?\",\n",
    "    \"Pregunta canónica 2?\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e305292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 179 interacciones o preguntas de contacto\n",
    "# se enviarán lotes de 50 en 50\n",
    "# luego cuando se hayan reducido, se unificarán las oraciones generales\n",
    "# y se volverá a solicitar al LLM que las reduzca una última vez\n",
    "# así nos aseguramos de que el LLM haya observado todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9cc8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contact questions:   0%|                                                                   | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contact questions: 100%|███████████████████████████████████████████████████████████| 4/4 [01:21<00:00, 20.39s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "slice_size = 50\n",
    "num_rows = len(df_operadores_pregunta_contacto)\n",
    "\n",
    "for i in tqdm(range(0, num_rows, slice_size), desc=\"Processing contact questions\"):\n",
    "    sliced_df = df_operadores_pregunta_contacto.iloc[i:i + slice_size]\n",
    "    utterances = sliced_df[\"ATA_TEXTO_TAGGED\"].tolist()\n",
    "\n",
    "    user_prompt = contact_prompt + str(utterances)\n",
    "\n",
    "    response = get_llm_answer(user_prompt)\n",
    "\n",
    "    parsed_response = json_repair.repair_json(\n",
    "        response,\n",
    "        return_objects=True,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    "    \n",
    "    temp_df = pd.DataFrame({\n",
    "        \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "    })\n",
    "    \n",
    "    temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "    temp_df_name = (\n",
    "        f\"reduccion_interacciones_operador/\"\n",
    "        f\"reduccion_pregunta/\"\n",
    "        f\"reduccion_contacto/v1/{i}_{i+len(sliced_df)-1}.csv\"\n",
    "    )\n",
    "\n",
    "    temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez procesados todas las 179 interacciones del operador de:\n",
    "# PREGUNTA / CONTACTO\n",
    "# como se enviaron en lotes de 50 en 50 y fueron guardados en csvs\n",
    "# ahora se van a concantenar los 4 csvs en uno solo y una última vez\n",
    "# se solicitará al LLM con el mismo prompt que reduzca las interacciones\n",
    "# esto nos dará las preguntas canónicas o base que ha hecho un operador\n",
    "# de la categoría pregunta/contacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7cf9fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  12 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 224.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "dir = \"reduccion_interacciones_operador/reduccion_pregunta/reduccion_contacto/v1\"\n",
    "all_csv = glob.glob(os.path.join(dir, \"*.csv\"))\n",
    "concat_df = pd.concat(map(pd.read_csv, all_csv), ignore_index=True)\n",
    "print(concat_df.info())\n",
    "concat_df.to_csv(dir+\"/concat_all_dfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como vemos, de todas las 179 interacciones de obtuvieron 12 preguntas canónicas\n",
    "# ahora se van a enviar las 12 preguntas al LLM para obtener las base, ya que el LLM\n",
    "# solo veía lotes de 50 entonces puede que existan preguntas muy parecidas\n",
    "import pandas as pd\n",
    "\n",
    "utterances = str(concat_df[\"canonical_questions\"].tolist())\n",
    "user_prompt = contact_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_contacto/v1/final_pregunta_contacto.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3854d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  4 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 160.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0267b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 4 preguntas canónicas de contacto\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_contacto/v1/final_pregunta_contacto.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70042a45",
   "metadata": {},
   "source": [
    "## Tipo_incidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26e6bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 135 entries, 2 to 4866\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  135 non-null    object\n",
      " 1   ACTOR             135 non-null    object\n",
      " 2   DIALOG_ACT        135 non-null    object\n",
      " 3   SUBACT            135 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# De Pregunta, reducir ahora Contacto\n",
    "df_operadores_pregunta_tipo = df_operadores_pregunta[df_operadores_pregunta[\"SUBACT\"] == \"tipo_incidente\"]\n",
    "df_operadores_pregunta_tipo.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0ab2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "type_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Question\n",
    "- SUBACT: Incident Type\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE QUESTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that request the SAME information.\n",
    "- Do NOT merge questions that request DIFFERENT information.\n",
    "- Write natural, neutral questions an operator would ask.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Canonical questions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_questions\": [\n",
    "    \"Pregunta canónica 1?\",\n",
    "    \"Pregunta canónica 2?\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fca81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 135 interacciones o preguntas de tipo de incidente\n",
    "# se enviarán lotes de 50 en 50\n",
    "# luego cuando se hayan reducido, se unificarán las oraciones generales\n",
    "# y se volverá a solicitar al LLM que las reduzca una última vez\n",
    "# así nos aseguramos de que el LLM haya observado todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84c197e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing incident type questions:   0%|                                                             | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing incident type questions: 100%|█████████████████████████████████████████████████████| 3/3 [00:48<00:00, 16.24s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "slice_size = 50\n",
    "num_rows = len(df_operadores_pregunta_tipo)\n",
    "\n",
    "for i in tqdm(range(0, num_rows, slice_size), desc=\"Processing incident type questions\"):\n",
    "    sliced_df = df_operadores_pregunta_tipo.iloc[i:i + slice_size]\n",
    "    utterances = sliced_df[\"ATA_TEXTO_TAGGED\"].tolist()\n",
    "\n",
    "    user_prompt = type_prompt + str(utterances)\n",
    "\n",
    "    response = get_llm_answer(user_prompt)\n",
    "\n",
    "    parsed_response = json_repair.repair_json(\n",
    "        response,\n",
    "        return_objects=True,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    "    \n",
    "    temp_df = pd.DataFrame({\n",
    "        \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "    })\n",
    "    \n",
    "    temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "    temp_df_name = (\n",
    "        f\"reduccion_interacciones_operador/\"\n",
    "        f\"reduccion_pregunta/\"\n",
    "        f\"reduccion_tipo_incidente/v1/{i}_{i+len(sliced_df)-1}.csv\"\n",
    "    )\n",
    "\n",
    "    temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b279eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez procesados todas las 179 interacciones del operador de:\n",
    "# PREGUNTA / CONTACTO\n",
    "# como se enviaron en lotes de 50 en 50 y fueron guardados en csvs\n",
    "# ahora se van a concantenar los 3 csvs en uno solo y una última vez\n",
    "# se solicitará al LLM con el mismo prompt que reduzca las interacciones\n",
    "# esto nos dará las preguntas canónicas o base que ha hecho un operador\n",
    "# de la categoría pregunta/contacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04bd0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  6 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 176.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "dir = \"reduccion_interacciones_operador/reduccion_pregunta/reduccion_tipo_incidente/v1\"\n",
    "all_csv = glob.glob(os.path.join(dir, \"*.csv\"))\n",
    "concat_df = pd.concat(map(pd.read_csv, all_csv), ignore_index=True)\n",
    "print(concat_df.info())\n",
    "concat_df.to_csv(dir+\"/concat_all_dfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e823186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como vemos, de todas las 179 interacciones de obtuvieron 6 preguntas canónicas\n",
    "# ahora se van a enviar las 6 preguntas al LLM para obtener las base, ya que el LLM\n",
    "# solo veía lotes de 50 entonces puede que existan preguntas muy parecidas\n",
    "import pandas as pd\n",
    "\n",
    "utterances = str(concat_df[\"canonical_questions\"].tolist())\n",
    "user_prompt = type_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_tipo_incidente/v1/final_pregunta_tipo_incidente.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b387a3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  2 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 144.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a3503db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 2 preguntas canónicas de confirmación\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_tipo_incidente/v1/final_pregunta_tipo_incidente.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c272b45",
   "metadata": {},
   "source": [
    "## Heridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419b2899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 56 entries, 6 to 4965\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  56 non-null     object\n",
      " 1   ACTOR             56 non-null     object\n",
      " 2   DIALOG_ACT        56 non-null     object\n",
      " 3   SUBACT            56 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# De Pregunta, reducir ahora Heridos\n",
    "df_operadores_pregunta_heridos = df_operadores_pregunta[df_operadores_pregunta[\"SUBACT\"] == \"heridos\"]\n",
    "df_operadores_pregunta_heridos.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1691a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "inj_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Question\n",
    "- SUBACT: Injured\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE QUESTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that request the SAME information.\n",
    "- Do NOT merge questions that request DIFFERENT information.\n",
    "- Write natural, neutral questions an operator would ask.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Canonical questions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_questions\": [\n",
    "    \"Pregunta canónica 1?\",\n",
    "    \"Pregunta canónica 2?\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28775adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 56 interacciones o preguntas de heridos\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_pregunta_heridos[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = inj_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_questions\": parsed_response[\"canonical_questions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_questions\"] = temp_df[\"canonical_questions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_heridos/v1/final_pregunta_heridos.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c66854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   canonical_questions  8 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3406c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 8 preguntas canónicas de heridos\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_pregunta/\"\n",
    "    \"reduccion_heridos/v1/final_pregunta_heridos.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda0c85",
   "metadata": {},
   "source": [
    "# Rutina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0375ce93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "SUBACT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "56a5d91e-6a76-44c8-9d42-b19ede309498",
       "rows": [
        [
         "rutina_operador",
         "154"
        ],
        [
         "cortesía",
         "36"
        ],
        [
         "otro",
         "6"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "SUBACT\n",
       "rutina_operador    154\n",
       "cortesía            36\n",
       "otro                 6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para Rutina, estos son los subactos\n",
    "df_operadores_rutina = df_operadores[df_operadores[\"DIALOG_ACT\"] == \"Rutina\"].copy()\n",
    "df_operadores_rutina[\"SUBACT\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89390d96",
   "metadata": {},
   "source": [
    "## Rutina Operador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3458e4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 154 entries, 26 to 4959\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  154 non-null    object\n",
      " 1   ACTOR             154 non-null    object\n",
      " 2   DIALOG_ACT        154 non-null    object\n",
      " 3   SUBACT            154 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# De Rutina, reducir primero rutina_operador\n",
    "df_operadores_rutina_operador = df_operadores_rutina[df_operadores_rutina[\"SUBACT\"] == \"rutina_operador\"]\n",
    "df_operadores_rutina_operador.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f24f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "rut_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Routine\n",
    "- SUBACT: Operator Routine\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE EXPRESSIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that perform the SAME routine function.\n",
    "- Do NOT merge expressions that perform DIFFERENT functions.\n",
    "- Write natural, neutral expressions an operator would use.\n",
    "- When an expression encodes a standard institutional formula (e.g., emergency center identification or service assurance), preserve that function in the canonical expression.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Expressions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_expressions\": [\n",
    "    \"Expresión canónica 1.\",\n",
    "    \"Expresión canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 154 interacciones o preguntas de rutina de operador\n",
    "# se enviarán lotes de 50 en 50\n",
    "# luego cuando se hayan reducido, se unificarán las oraciones generales\n",
    "# y se volverá a solicitar al LLM que las reduzca una última vez\n",
    "# así nos aseguramos de que el LLM haya observado todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b0da7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing operator routines: 100%|███████████████████████████████████████████████████████████| 4/4 [00:43<00:00, 10.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "slice_size = 50\n",
    "num_rows = len(df_operadores_rutina_operador)\n",
    "\n",
    "for i in tqdm(range(0, num_rows, slice_size), desc=\"Processing operator routines\"):\n",
    "    sliced_df = df_operadores_rutina_operador.iloc[i:i + slice_size]\n",
    "    utterances = sliced_df[\"ATA_TEXTO_TAGGED\"].tolist()\n",
    "\n",
    "    user_prompt = rut_prompt + str(utterances)\n",
    "\n",
    "    response = get_llm_answer(user_prompt)\n",
    "\n",
    "    parsed_response = json_repair.repair_json(\n",
    "        response,\n",
    "        return_objects=True,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    "    \n",
    "    temp_df = pd.DataFrame({\n",
    "        \"canonical_expressions\": parsed_response[\"canonical_expressions\"]\n",
    "    })\n",
    "    \n",
    "    temp_df[\"canonical_expressions\"] = temp_df[\"canonical_expressions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "    temp_df_name = (\n",
    "        f\"reduccion_interacciones_operador/\"\n",
    "        f\"reduccion_rutina/\"\n",
    "        f\"reduccion_rutina_operador/v1/{i}_{i+len(sliced_df)-1}.csv\"\n",
    "    )\n",
    "\n",
    "    temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez procesados todas las 154 interacciones del operador de:\n",
    "# RUTINA / RUTINA_OPERADOR\n",
    "# como se enviaron en lotes de 50 en 50 y fueron guardados en csvs\n",
    "# ahora se van a concantenar los 4 csvs en uno solo y una última vez\n",
    "# se solicitará al LLM con el mismo prompt que reduzca las interacciones\n",
    "# esto nos dará las preguntas canónicas o base que ha hecho un operador\n",
    "# de la categoría rutina/rutina_operador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8623e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 1 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   canonical_expressions  14 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 240.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "dir = \"reduccion_interacciones_operador/reduccion_rutina/reduccion_rutina_operador/v1\"\n",
    "\n",
    "all_csv = glob.glob(os.path.join(dir, \"*.csv\"))\n",
    "concat_df = pd.concat(map(pd.read_csv, all_csv), ignore_index=True)\n",
    "print(concat_df.info())\n",
    "concat_df.to_csv(dir+\"/concat_all_dfs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f7e9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como vemos, de todas las 154 interacciones de obtuvieron 14 preguntas canónicas\n",
    "# ahora se van a enviar las 14 preguntas al LLM para obtener las base, ya que el LLM\n",
    "# solo veía lotes de 50 entonces puede que existan preguntas muy parecidas\n",
    "import pandas as pd\n",
    "\n",
    "utterances = str(concat_df[\"canonical_expressions\"].tolist())\n",
    "user_prompt = rut_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_expressions\": parsed_response[\"canonical_expressions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_expressions\"] = temp_df[\"canonical_expressions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_rutina/\"\n",
    "    \"reduccion_rutina_operador/v1/final_rutina_operador.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf9b607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   canonical_expressions  4 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 160.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95424ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 4 rutinas canónicas del operador\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_rutina/\"\n",
    "    \"reduccion_rutina_operador/v1/final_rutina_operador.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05edd25",
   "metadata": {},
   "source": [
    "## Cortesía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b7bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36 entries, 217 to 4961\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  36 non-null     object\n",
      " 1   ACTOR             36 non-null     object\n",
      " 2   DIALOG_ACT        36 non-null     object\n",
      " 3   SUBACT            36 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# De Rutina, reducir ahora cortesía\n",
    "df_operadores_rutina_cortesia = df_operadores_rutina[df_operadores_rutina[\"SUBACT\"] == \"cortesía\"]\n",
    "df_operadores_rutina_cortesia.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80310fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "court_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Routine\n",
    "- SUBACT: Courtesy \n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE EXPRESSIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that perform the SAME routine function.\n",
    "- Do NOT merge expressions that perform DIFFERENT functions.\n",
    "- Write natural, neutral expressions an operator would use.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Expressions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_expressions\": [\n",
    "    \"Expresión canónica 1.\",\n",
    "    \"Expresión canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c9be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 36 interacciones o preguntas de heridos\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_rutina_cortesia[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = court_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_expressions\": parsed_response[\"canonical_expressions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_expressions\"] = temp_df[\"canonical_expressions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_rutina/\"\n",
    "    \"reduccion_cortesia/v1/final_rutina_cortesia.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbdcfc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 1 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   canonical_expressions  11 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 216.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44182183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 11 rutinas canónicas de cortesía\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_rutina/\"\n",
    "    \"reduccion_cortesia/v1/final_rutina_cortesia.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa60e73",
   "metadata": {},
   "source": [
    "## Otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e577ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6 entries, 374 to 4699\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  6 non-null      object\n",
      " 1   ACTOR             6 non-null      object\n",
      " 2   DIALOG_ACT        6 non-null      object\n",
      " 3   SUBACT            6 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 240.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Rutina, reducir ahora otro\n",
    "df_operadores_rutina_otro = df_operadores_rutina[df_operadores_rutina[\"SUBACT\"] == \"otro\"]\n",
    "df_operadores_rutina_otro.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e6c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "other_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Routine\n",
    "- SUBACT: Other \n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE EXPRESSIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring intents, but do not over-simplify.\n",
    "- Merge different phrasings that perform the SAME routine function.\n",
    "- Do NOT merge expressions that perform DIFFERENT functions.\n",
    "- Write natural, neutral expressions an operator would use.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Expressions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_expressions\": [\n",
    "    \"Expresión canónica 1.\",\n",
    "    \"Expresión canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e220652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 36 interacciones o preguntas de heridos\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_rutina_otro[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = other_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_expressions\": parsed_response[\"canonical_expressions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_expressions\"] = temp_df[\"canonical_expressions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_rutina/\"\n",
    "    \"reduccion_otro/v1/final_rutina_otro.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8eba79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 1 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   canonical_expressions  4 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 160.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 4 rutinas canónicas de otro\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_rutina/\"\n",
    "    \"reduccion_otro/v1/final_rutina_otro.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f7215",
   "metadata": {},
   "source": [
    "# Descripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24fed0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "SUBACT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4c433079-da85-4658-8cc9-4a72032b917d",
       "rows": [
        [
         "otro",
         "63"
        ],
        [
         "localización",
         "18"
        ],
        [
         "tipo_incidente",
         "5"
        ],
        [
         "evolución",
         "5"
        ],
        [
         "heridos",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "SUBACT\n",
       "otro              63\n",
       "localización      18\n",
       "tipo_incidente     5\n",
       "evolución          5\n",
       "heridos            2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para Descripción, estos son los subactos\n",
    "df_operadores_descripcion = df_operadores[df_operadores[\"DIALOG_ACT\"] == \"Descripción\"].copy()\n",
    "df_operadores_descripcion[\"SUBACT\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159d900",
   "metadata": {},
   "source": [
    "## Otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f06a9aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 63 entries, 260 to 4754\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  63 non-null     object\n",
      " 1   ACTOR             63 non-null     object\n",
      " 2   DIALOG_ACT        63 non-null     object\n",
      " 3   SUBACT            63 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# De Descripción, reducir primero otro\n",
    "df_operadores_descripcion_otro = df_operadores_descripcion[df_operadores_descripcion[\"SUBACT\"] == \"otro\"]\n",
    "df_operadores_descripcion_otro.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e42a20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "other_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Description\n",
    "- SUBACT: Other\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE DESCRIPTIVE STATEMENTS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Ignore conversational routines, greetings, fillers, confirmations, transfers, or administrative talk.\n",
    "- Abstract recurring descriptive content, but do not over-simplify.\n",
    "- Merge different phrasings that describe the SAME situation or information.\n",
    "- Write clear, neutral descriptive statements spoken directly by the operator.\n",
    "- Do NOT describe the operator's actions; write the statements the operator would say.\n",
    "- Descriptions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_descriptions\": [\n",
    "    \"Descripción canónica 1.\",\n",
    "    \"Descripción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bace4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 63 interacciones o preguntas de heridos\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_descripcion_otro[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = other_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_descriptions\": parsed_response[\"canonical_descriptions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_descriptions\"] = temp_df[\"canonical_descriptions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_otro/v1/final_descripcion_otro.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44b1c6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_descriptions  6 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f803c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 6 descripciones canónicas de otros\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_otro/v1/final_descripcion_otro.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225e096a",
   "metadata": {},
   "source": [
    "## Localización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf1af052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18 entries, 184 to 4606\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  18 non-null     object\n",
      " 1   ACTOR             18 non-null     object\n",
      " 2   DIALOG_ACT        18 non-null     object\n",
      " 3   SUBACT            18 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 720.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Descripción, reducir ahora localización\n",
    "df_operadores_descripcion_localizacion = df_operadores_descripcion[df_operadores_descripcion[\"SUBACT\"] == \"localización\"]\n",
    "df_operadores_descripcion_localizacion.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40be2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "loc_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Description\n",
    "- SUBACT: Localization\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE DESCRIPTIVE STATEMENTS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Only consider utterances that describe the location of the incident or the emergency.\n",
    "- Abstract recurring location descriptions, but do not over-simplify.\n",
    "- Merge different phrasings that describe the SAME type of location information.\n",
    "- Write clear, neutral descriptive statements spoken directly by the operator.\n",
    "- Do NOT describe the operator's actions; write the statements the operator would say.\n",
    "- Descriptions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_descriptions\": [\n",
    "    \"Descripción canónica 1.\",\n",
    "    \"Descripción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e6c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 18 interacciones o descripciones de localización\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_descripcion_localizacion[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = loc_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_descriptions\": parsed_response[\"canonical_descriptions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_descriptions\"] = temp_df[\"canonical_descriptions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_localizacion/v1/final_descripcion_localizacion.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "669c9faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_descriptions  10 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 208.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 10 descripciones canónicas de localización\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_localizacion/v1/final_descripcion_localizacion.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb3994",
   "metadata": {},
   "source": [
    "## Tipo_incidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439250c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, 104 to 2577\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  5 non-null      object\n",
      " 1   ACTOR             5 non-null      object\n",
      " 2   DIALOG_ACT        5 non-null      object\n",
      " 3   SUBACT            5 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 200.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Descripción, reducir ahora tipo_incidente\n",
    "df_operadores_descripcion_tipo_incidente = df_operadores_descripcion[df_operadores_descripcion[\"SUBACT\"] == \"tipo_incidente\"]\n",
    "df_operadores_descripcion_tipo_incidente.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7b4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "type_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Description\n",
    "- SUBACT: Incident Type\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE DESCRIPTIVE STATEMENTS\n",
    "that describe the TYPE OF INCIDENT,\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Only consider utterances that clearly describe the nature or type of the incident.\n",
    "- Ignore questions, routines, transfers, greetings, or administrative talk.\n",
    "- Abstract the incident type; remove specific details, entities, or values.\n",
    "- Merge different phrasings that describe the SAME type of incident.\n",
    "- Write clear, neutral descriptive statements spoken directly by the operator.\n",
    "- Do NOT describe the operator's actions or mention the alertant.\n",
    "- Descriptions must be general and must not include specific names, places, institutions, brands, body parts, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_descriptions\": [\n",
    "    \"Descripción canónica 1.\",\n",
    "    \"Descripción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41fe833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 5 interacciones o descripciones de localización\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_descripcion_tipo_incidente[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = type_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_descriptions\": parsed_response[\"canonical_descriptions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_descriptions\"] = temp_df[\"canonical_descriptions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_tipo_incidente/v1/final_descripcion_tipo_incidente.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03d34a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_descriptions  2 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 144.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bbb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 2 descripciones canónicas de tipo de incidente\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_tipo_incidente/v1/final_descripcion_tipo_incidente.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f40e96",
   "metadata": {},
   "source": [
    "## Evolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc6dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5 entries, 615 to 2745\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  5 non-null      object\n",
      " 1   ACTOR             5 non-null      object\n",
      " 2   DIALOG_ACT        5 non-null      object\n",
      " 3   SUBACT            5 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 200.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Descripción, reducir ahora evolución\n",
    "df_operadores_descripcion_evolucion = df_operadores_descripcion[df_operadores_descripcion[\"SUBACT\"] == \"evolución\"]\n",
    "df_operadores_descripcion_evolucion.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "evo_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Description\n",
    "- SUBACT: Incident Evolution\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE DESCRIPTIVE STATEMENTS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Only consider utterances that clearly describe the incident evolution.\n",
    "- Ignore questions, routines, transfers, greetings, or administrative talk.\n",
    "- Merge different phrasings that describe the SAME evolution of incident.\n",
    "- Write clear, neutral descriptive statements spoken directly by the operator.\n",
    "- Do NOT describe the operator's actions or mention the alertant.\n",
    "- Descriptions must be general and must not include specific names, places, institutions, brands, body parts, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_descriptions\": [\n",
    "    \"Descripción canónica 1.\",\n",
    "    \"Descripción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9f72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 5 interacciones o descripciones de localización\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_descripcion_evolucion[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = evo_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_descriptions\": parsed_response[\"canonical_descriptions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_descriptions\"] = temp_df[\"canonical_descriptions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_evolucion/v1/final_descripcion_evolucion.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dffd043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_descriptions  3 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 152.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae302c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 3 descripciones canónicas de evolución\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_evolucion/v1/final_descripcion_evolucion.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda7dc2",
   "metadata": {},
   "source": [
    "## Heridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11710147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2 entries, 1081 to 2342\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  2 non-null      object\n",
      " 1   ACTOR             2 non-null      object\n",
      " 2   DIALOG_ACT        2 non-null      object\n",
      " 3   SUBACT            2 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 80.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Descripción, reducir ahora heridos\n",
    "df_operadores_descripcion_heridos = df_operadores_descripcion[df_operadores_descripcion[\"SUBACT\"] == \"heridos\"]\n",
    "df_operadores_descripcion_heridos.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "696874c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "inj_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Description\n",
    "- SUBACT: Injured\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE DESCRIPTIVE STATEMENTS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Only consider utterances that clearly describe injured people or injures.\n",
    "- Ignore questions, routines, transfers, greetings, or administrative talk.\n",
    "- Merge different phrasings that describe the SAME.\n",
    "- Write clear, grammatically correct, neutral descriptive statements spoken directly by the operator.\n",
    "- Do NOT describe the operator's actions or mention the alertant.\n",
    "- Descriptions must be general and must not include specific names, places, institutions, brands, body parts, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_descriptions\": [\n",
    "    \"Descripción canónica 1.\",\n",
    "    \"Descripción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9411da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 5 interacciones o descripciones de localización\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_descripcion_heridos[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = inj_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_descriptions\": parsed_response[\"canonical_descriptions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_descriptions\"] = temp_df[\"canonical_descriptions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_heridos/v1/final_descripcion_heridos.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adbc5775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_descriptions  2 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 144.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b7ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 2 descripciones canónicas de heridos\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_descripcion/\"\n",
    "    \"reduccion_heridos/v1/final_descripcion_heridos.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa2ed7",
   "metadata": {},
   "source": [
    "# Orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b10f60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "SUBACT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "70bf0fe4-71f0-48cd-90cb-265b87afe200",
       "rows": [
        [
         "permanecer_línea",
         "23"
        ],
        [
         "otro",
         "9"
        ],
        [
         "seguir_instrucciones",
         "4"
        ],
        [
         "acción_seguridad",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "SUBACT\n",
       "permanecer_línea        23\n",
       "otro                     9\n",
       "seguir_instrucciones     4\n",
       "acción_seguridad         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para Orden, estos son los subactos\n",
    "df_operadores_orden = df_operadores[df_operadores[\"DIALOG_ACT\"] == \"Orden\"].copy()\n",
    "df_operadores_orden[\"SUBACT\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a35cb2",
   "metadata": {},
   "source": [
    "## Permanecer en línea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c30904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23 entries, 422 to 4326\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  23 non-null     object\n",
      " 1   ACTOR             23 non-null     object\n",
      " 2   DIALOG_ACT        23 non-null     object\n",
      " 3   SUBACT            23 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 920.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Orden, reducir permanecer_línea\n",
    "df_operadores_orden_linea = df_operadores_orden[df_operadores_orden[\"SUBACT\"] == \"permanecer_línea\"]\n",
    "df_operadores_orden_linea.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "789142d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "stay_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Order\n",
    "- SUBACT: Stay on line\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE INSTRUCTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring directive intents, but do not over-simplify.\n",
    "- Merge different phrasings that instruct the SAME action.\n",
    "- Do NOT merge instructions that require DIFFERENT actions.\n",
    "- Write clear, neutral instructions an operator would give.\n",
    "- Preserve safety-related or procedural intent when present.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Instructions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_instructions\": [\n",
    "    \"Instrucción canónica 1.\",\n",
    "    \"Instrucción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4401b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 23 interacciones o descripciones de localización\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_orden_linea[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = stay_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_instructions\": parsed_response[\"canonical_instructions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_instructions\"] = temp_df[\"canonical_instructions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_orden/\"\n",
    "    \"reduccion_permanecer_linea/v1/final_orden_permanecer_linea.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d37040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_instructions  3 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 152.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad32b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 3 ordenes canónicas de permanecer en línea\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_orden/\"\n",
    "    \"reduccion_permanecer_linea/v1/final_orden_permanecer_linea.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949e05c",
   "metadata": {},
   "source": [
    "## Otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1fd22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9 entries, 14 to 3319\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  9 non-null      object\n",
      " 1   ACTOR             9 non-null      object\n",
      " 2   DIALOG_ACT        9 non-null      object\n",
      " 3   SUBACT            9 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 360.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Orden, reducir ahora otro\n",
    "df_operadores_orden_otro = df_operadores_orden[df_operadores_orden[\"SUBACT\"] == \"otro\"]\n",
    "df_operadores_orden_otro.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41bcb8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "order_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Order\n",
    "- SUBACT: Other\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE INSTRUCTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring directive intents, but do not over-simplify.\n",
    "- Merge different phrasings that instruct the SAME action.\n",
    "- Do NOT merge instructions that require DIFFERENT actions.\n",
    "- Write clear, neutral instructions an operator would give.\n",
    "- Preserve safety-related or procedural intent when present.\n",
    "- Ignore utterances that are not genuine operator instructions.\n",
    "- Instructions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_instructions\": [\n",
    "    \"Instrucción canónica 1.\",\n",
    "    \"Instrucción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1876c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 9 interacciones o descripciones de localización\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_orden_otro[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = order_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_instructions\": parsed_response[\"canonical_instructions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_instructions\"] = temp_df[\"canonical_instructions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_orden/\"\n",
    "    \"reduccion_otro/v1/final_orden_otro.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe275b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_instructions  2 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 144.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f651ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 2 ordenes canónicas de otro\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_orden/\"\n",
    "    \"reduccion_otro/v1/final_orden_otro.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8f7e4",
   "metadata": {},
   "source": [
    "## Seguir instrucciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9ee96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4 entries, 10 to 4354\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  4 non-null      object\n",
      " 1   ACTOR             4 non-null      object\n",
      " 2   DIALOG_ACT        4 non-null      object\n",
      " 3   SUBACT            4 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 160.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Orden, reducir ahora seguir_instrucciones\n",
    "df_operadores_orden_instrucciones = df_operadores_orden[df_operadores_orden[\"SUBACT\"] == \"seguir_instrucciones\"]\n",
    "df_operadores_orden_instrucciones.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28a3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "inst_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Order\n",
    "- SUBACT: Follow Instructions\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE INSTRUCTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring directive intents, but do not over-simplify.\n",
    "- Merge different phrasings that instruct the SAME action.\n",
    "- Do NOT merge instructions that require DIFFERENT actions.\n",
    "- Write clear, neutral instructions an operator would give.\n",
    "- Preserve safety-related or procedural intent when present.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Instructions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_instructions\": [\n",
    "    \"Instrucción canónica 1.\",\n",
    "    \"Instrucción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71958aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 4 interacciones o descripciones de localización\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_orden_instrucciones[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = inst_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_instructions\": parsed_response[\"canonical_instructions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_instructions\"] = temp_df[\"canonical_instructions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_orden/\"\n",
    "    \"reduccion_seguir_instrucciones/v1/final_orden_seguir_instruciones.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "535a6245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_instructions  3 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 152.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f85509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuvieron 3 ordenes canónicas de seguir instrucciones\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_orden/\"\n",
    "    \"reduccion_seguir_instrucciones/v1/final_orden_seguir_instruciones.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f4fa2e",
   "metadata": {},
   "source": [
    "## Acción de seguridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f093dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2 entries, 852 to 2125\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   ATA_TEXTO_TAGGED  2 non-null      object\n",
      " 1   ACTOR             2 non-null      object\n",
      " 2   DIALOG_ACT        2 non-null      object\n",
      " 3   SUBACT            2 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 80.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# De Orden, reducir ahora seguir_instrucciones\n",
    "df_operadores_orden_seguridad = df_operadores_orden[df_operadores_orden[\"SUBACT\"] == \"acción_seguridad\"]\n",
    "df_operadores_orden_seguridad.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ecc4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt para el LLM\n",
    "seg_prompt = \"\"\"You will be given real utterances produced by OPERATORS at an emergency center.\n",
    "All utterances belong to:\n",
    "- DIALOG ACT: Order\n",
    "- SUBACT: Security Action\n",
    "\n",
    "The utterances may be incomplete or noisy.\n",
    "Your task is to reduce them into a distinct set of REPRESENTATIVE BASE INSTRUCTIONS\n",
    "written in SPANISH.\n",
    "\n",
    "Guidelines:\n",
    "- Abstract recurring directive intents, but do not over-simplify.\n",
    "- Merge different phrasings that instruct the SAME action.\n",
    "- Do NOT merge instructions that require DIFFERENT actions.\n",
    "- Write clear, neutral instructions an operator would give.\n",
    "- Preserve safety-related or procedural intent when present.\n",
    "- Write the instructions as direct imperatives spoken to the caller; do NOT describe the act of giving an instruction.\n",
    "- Ignore utterances that are not genuinely related to the specified DIALOG ACT and SUBACT.\n",
    "- Instructions must be general and must not include specific names, places, institutions, numbers, or unique identifiers.\n",
    "- Do NOT add labels, explanations, or extra text.\n",
    "- Do NOT use placeholders or brackets.\n",
    "\n",
    "Output JSON (STRICT):\n",
    "\n",
    "{\n",
    "  \"canonical_instructions\": [\n",
    "    \"Instrucción canónica 1.\",\n",
    "    \"Instrucción canónica 2.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Utterances:\n",
    "\"\"\"\n",
    "\n",
    "# poner al final\n",
    "# Reasoning: Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6a935f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como son 4 interacciones o descripciones de localización\n",
    "# se enviarán todas en una sola interacción\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "utterances = str(df_operadores_orden_seguridad[\"ATA_TEXTO_TAGGED\"].tolist())\n",
    "user_prompt = seg_prompt + str(utterances)\n",
    "response = get_llm_answer(user_prompt)\n",
    "parsed_response = json_repair.repair_json(\n",
    "    response,\n",
    "    return_objects=True,\n",
    "    ensure_ascii=False\n",
    ")\n",
    "\n",
    "temp_df = pd.DataFrame({\n",
    "    \"canonical_instructions\": parsed_response[\"canonical_instructions\"]\n",
    "})\n",
    "\n",
    "temp_df[\"canonical_instructions\"] = temp_df[\"canonical_instructions\"].str.replace('\"', '', regex=False)\n",
    "\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_orden/\"\n",
    "    \"reduccion_accion_seguridad/v1/final_orden_accion_seguridad.csv\"\n",
    ")\n",
    "\n",
    "temp_df.to_csv(temp_df_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d17e684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 1 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   canonical_instructions  1 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 136.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399aca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, se obtuviero 1 orden canónica de acción de seguridad\n",
    "temp_df_name = (\n",
    "    \"reduccion_interacciones_operador/\"\n",
    "    \"reduccion_orden/\"\n",
    "    \"reduccion_accion_seguridad/v1/final_orden_accion_seguridad.xlsx\"\n",
    ")\n",
    "temp_df.to_excel(temp_df_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
