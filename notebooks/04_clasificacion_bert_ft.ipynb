{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv venv --python=python3.10\n",
    "# source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entonces la idea nueva es, identificar la interacción o las interacciones más \n",
    "# largas de los Alertantes, obtener palabras clave, con esas palabras clave pedir \n",
    "# a un LLM que genere preguntas (esas preguntas deben relacionarse con las \n",
    "# palabras clave y no deben contener NERs) y luego comparar semánticamente \n",
    "# las preguntas generadas por el LLM con la base de datos de preguntas reales, \n",
    "# para lanzarlas como opción para que diga el operador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero se tiene que armar el dataset\n",
    "# Se me ocurren dos ideas, como solo vamos a trabajar la siguiente pregunta\n",
    "# que debe decir el operador y se va a consultar al LLM que genere una posible pregunta\n",
    "# incluyendo un tipo de COT en el prompt con los metadatos que tienen las interacciones\n",
    "# y luego comparar esa pregunta semánticamente con la base de preguntas normalizadas para dar unas opciones\n",
    "# al operador, y finalmente para la evaluación comparar tal vez la similitud semántica entre la opción escogida\n",
    "# o la pregunta que ha generado el LLM contra la pregunta actual que ha dicho el operador.\n",
    "\n",
    "# Entonces podría ser una primera prueba enviar todo el contexto previo de la conversación hasta antes de\n",
    "# lo que dice el alertante en el prompt.\n",
    "\n",
    "# Y el otro experimento solo enviando lo que dice el alertante, sin contexto previo.\n",
    "\n",
    "# Entonces los datasets del primer experimento se van a guardar en v6/datasets/v1\n",
    "# y los del segundo experimento en v6/datasets/v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c992d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero voy a armar el módulo de recuperación por similitud semántica\n",
    "# no voy a ocupar Milvus, Pinecone, etc. porque no son muchos registros\n",
    "# y no hay mucho tiempo xd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218749b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como al cargar el LLM gpt oss de 20b se necesitan las dos primeras gpus\n",
    "# casi a full, para el resto voy a ocupar la 3era gráfica\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa74f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 1)\n"
     ]
    }
   ],
   "source": [
    "# Primero voy a unificar en una sola todas las preguntas generales de los\n",
    "# operadores\n",
    "import pandas as pd\n",
    "\n",
    "df_pregunta_confirmación = pd.read_csv(\"../vllm_experiments/reduccion_interacciones_operador/reduccion_pregunta/reduccion_confirmacion/v1/final_pregunta_confirmacion.csv\")\n",
    "df_pregunta_contacto = pd.read_csv(\"../vllm_experiments/reduccion_interacciones_operador/reduccion_pregunta/reduccion_contacto/v1/final_pregunta_contacto.csv\")\n",
    "df_pregunta_heridos = pd.read_csv(\"../vllm_experiments/reduccion_interacciones_operador/reduccion_pregunta/reduccion_heridos/v1/final_pregunta_heridos.csv\")\n",
    "df_pregunta_localizacion = pd.read_csv(\"../vllm_experiments/reduccion_interacciones_operador/reduccion_pregunta/reduccion_localizacion/v1/final_pregunta_localizacion.csv\")\n",
    "df_pregunta_otro = pd.read_csv(\"../vllm_experiments/reduccion_interacciones_operador/reduccion_pregunta/reduccion_otro/v1/final_pregunta_otro.csv\")\n",
    "df_pregunta_tipo_incidente = pd.read_csv(\"../vllm_experiments/reduccion_interacciones_operador/reduccion_pregunta/reduccion_tipo_incidente/v1/final_pregunta_tipo_incidente.csv\")\n",
    "\n",
    "concat_df = pd.concat([df_pregunta_confirmación, df_pregunta_contacto, df_pregunta_heridos,\n",
    "                       df_pregunta_localizacion, df_pregunta_otro, df_pregunta_tipo_incidente])\n",
    "\n",
    "concat_df = concat_df.drop_duplicates(subset=['canonical_questions'])\n",
    "print(concat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22396c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-large',\n",
    "                            device=\"cuda\")\n",
    "\n",
    "questions = concat_df[\"canonical_questions\"].to_list()\n",
    "formatted_questions = [\"query: \" + question for question in questions]\n",
    "corpus_embeddings = model.encode(formatted_questions, normalize_embeddings=True)\n",
    "# corpus_embeddings = corpus_embeddings.to(\"cuda\")\n",
    "# corpus_embeddings = util.normalize_embeddings(corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c277e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para pruebas\n",
    "query = \"query: gas\"\n",
    "query_embeddings = model.encode(query, normalize_embeddings=True)\n",
    "# query_embeddings = query_embeddings.to(\"cuda\")\n",
    "# query_embeddings = util.normalize_embeddings(query_embeddings)\n",
    "\n",
    "hits = util.semantic_search(query_embeddings, corpus_embeddings, top_k=3)\n",
    "top_hits = hits[0]\n",
    "\n",
    "for hit in top_hits:\n",
    "    corpus_id = hit[\"corpus_id\"]\n",
    "    score = hit[\"score\"]\n",
    "    texto = questions[corpus_id]\n",
    "    print(f\"Score: {score:.4f} | Pregunta: {texto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f1df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para extraer las n preguntas parecidas\n",
    "\n",
    "def retrieve_real_questions(question):\n",
    "    formatted_query = f\"query: {question}\"\n",
    "    query_embedding = model.encode(formatted_query, normalize_embeddings=True)\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    top_hits = hits[0]\n",
    "    related_real_questions = []\n",
    "    scores = []\n",
    "    \n",
    "    for hit in top_hits:\n",
    "        corpus_id = hit[\"corpus_id\"]\n",
    "        score = hit[\"score\"]\n",
    "        text = questions[corpus_id]\n",
    "        related_real_questions.append(text)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return related_real_questions, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9a5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar los datasets iniciales\n",
    "# como no vamos a entrenar ningún modelo\n",
    "# solo vamos a formatear el dataset principal\n",
    "# para hacer la inferencia\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"../vllm_experiments/processed_llm_output_anonimized_clean.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ae536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d48bfa3d",
   "metadata": {},
   "source": [
    "# Primer experimento, enviando contexto previo al prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04b30b",
   "metadata": {},
   "source": [
    "## Preparando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06dc9920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# para generar el dataset del primer experimento\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe_keywords = pipeline(\n",
    "    \"text2text-generation\", \n",
    "    model=\"UDA-LIDI/barto_emergency_multi_purpose\",\n",
    "    device=0\n",
    ")\n",
    "\n",
    "def get_keywords(text):\n",
    "    return pipe_keywords(\"Extrae las palabras clave de la emergencia: \" + text)\n",
    "\n",
    "def _create_context_sample(actor, text):\n",
    "    return f\"ACTOR: {actor} TEXT: {text}\"\n",
    "\n",
    "def make_context(row):\n",
    "    return _create_context_sample(\n",
    "        row.ACTOR,\n",
    "        row.ATA_TEXTO_TAGGED,\n",
    "    )\n",
    "\n",
    "def context_slide_window(tmp_df):\n",
    "    aux_context = \"\"\n",
    "    context = []\n",
    "    samples = []\n",
    "    keywords = []    \n",
    "    labels = []\n",
    " \n",
    "    rows = list(tmp_df.itertuples())\n",
    "\n",
    "    for i in range(len(rows) - 1):\n",
    "        current = rows[i]\n",
    "        next_turn = rows[i + 1]\n",
    "\n",
    "        if i > 0:\n",
    "            aux_context += make_context(rows[i - 1]) + \" \\n \"\n",
    "            # context.append(make_context(rows[i - 1]))\n",
    "\n",
    "        if current.COMBINED == \"Alertante-Descripción-tipo_incidente\":\n",
    "            context.append(aux_context)\n",
    "            samples.append(make_context(current))\n",
    "            keywords.append(get_keywords(current.ATA_TEXTO_TAGGED)[0][\"generated_text\"])\n",
    "            labels.append(make_context(next_turn))\n",
    "            break\n",
    "            \n",
    "    return context, samples, keywords, labels\n",
    "\n",
    "def prepare_datasets_for_training(dataframe):\n",
    "    unique_ids = dataframe[\"TRA_ID\"].unique()\n",
    "    final_context = []\n",
    "    final_samples = []\n",
    "    final_keywords = []    \n",
    "    final_labels = []\n",
    "    for id in unique_ids:\n",
    "        temp_df = dataframe[dataframe[\"TRA_ID\"] == id].copy()\n",
    "        temp_df[\"COMBINED\"] = temp_df[\"ACTOR\"] + \"-\" + temp_df[\"DIALOG_ACT\"] + \"-\" + temp_df[\"SUBACT\"]\n",
    "        aux_combined = temp_df[\"COMBINED\"].to_list()\n",
    "        if \"Alertante-Descripción-tipo_incidente\" in aux_combined:\n",
    "            train_c, train_s, train_k, train_labs = context_slide_window(temp_df)\n",
    "            final_context += train_c\n",
    "            final_samples += train_s\n",
    "            final_keywords += train_k\n",
    "            final_labels += train_labs\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        \"prepared_context\": final_context,\n",
    "        \"prepared_samples\": final_samples,\n",
    "        \"prepared_keywords\": final_keywords,\n",
    "        \"prepared_labels\": final_labels\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7e7a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "prepared_dataset = prepare_datasets_for_training(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff475ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172, 4)\n"
     ]
    }
   ],
   "source": [
    "print(prepared_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ae726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# por qué hay menos registros que las 250 conversaciones iniciales\n",
    "# esto es porque yo filtré para encontrar únicamente las interacciones\n",
    "# donde esa interacción la haya dicho un alertante y fue etiquetada\n",
    "# como una descripción y un subacto de \"tipo_incidente\"\n",
    "\n",
    "# si bien todas las conversaciones deberían tener al menos una interacción\n",
    "# de ese tipo, revisando algunos ejemplos, hay alertantes que para describir\n",
    "# lo que está pasando describen directamente heridos o describen síntomas\n",
    "# y fueron etiquetadas con otro subacto, como descripción de síntomas\n",
    "# o descripción de heridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c73d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "7bbab15c-9110-4aee-b301-58d561d7f10e",
       "rows": [
        [
         "prepared_context",
         "ACTOR: Operador TEXT: emergencia \n ACTOR: Alertante TEXT: buenos dias hagame un favor me puede mandar un patrullero \n ACTOR: Operador TEXT: que sucede señore que le sucede \n "
        ],
        [
         "prepared_samples",
         "ACTOR: Alertante TEXT: esta un carro parqueado y un par de jovenes comenzaron a tirar piedras y me rompieron el parabrisas y estan aqui yo no se quienes son"
        ],
        [
         "prepared_keywords",
         "tirar piedras rompieron parabrisas"
        ],
        [
         "prepared_labels",
         "ACTOR: Operador TEXT: le agredieron"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "prepared_context     ACTOR: Operador TEXT: emergencia \\n ACTOR: Ale...\n",
       "prepared_samples     ACTOR: Alertante TEXT: esta un carro parqueado...\n",
       "prepared_keywords                   tirar piedras rompieron parabrisas\n",
       "prepared_labels                    ACTOR: Operador TEXT: le agredieron\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_dataset.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e09ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACTOR: Operador TEXT: emergencia \\n ACTOR: Alertante TEXT: buenos dias hagame un favor me puede mandar un patrullero \\n ACTOR: Operador TEXT: que sucede señore que le sucede \\n '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_dataset.iloc[0][\"prepared_context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679599a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACTOR: Alertante TEXT: esta un carro parqueado y un par de jovenes comenzaron a tirar piedras y me rompieron el parabrisas y estan aqui yo no se quienes son'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_dataset.iloc[0][\"prepared_samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f156cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tirar piedras rompieron parabrisas'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_dataset.iloc[0][\"prepared_keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a31dbbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACTOR: Operador TEXT: le agredieron'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_dataset.iloc[0][\"prepared_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar el dataset preparado\n",
    "# prepared_dataset.to_csv(\"datasets/v1/prepared_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7b23d",
   "metadata": {},
   "source": [
    "## Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e149f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora si a realizar inferencia armando un COT para solicitar al LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe03023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172 entries, 0 to 171\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   prepared_context   172 non-null    object\n",
      " 1   prepared_samples   172 non-null    object\n",
      " 2   prepared_keywords  172 non-null    object\n",
      " 3   prepared_labels    172 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 5.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_csv(\"datasets/v1/prepared_dataset.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fee6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# este es el cliente del gpt oss que está corriendo como\n",
    "# servicio en el hpc\n",
    "from openai import OpenAI\n",
    "\n",
    "system_prompt = \"\"\"You are an expert emergency call operator assistant.\n",
    "Your task is to determine the most appropriate next question that an emergency operator should ask.\n",
    "You must reason based on operational emergency protocols.\n",
    "Do not include names, addresses, or personal identifiable information.\n",
    "Output only one concise and natural question in Spanish.\n",
    "Reasoning: high\n",
    "\"\"\"\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:8010/v1\", api_key=\"EMPTY\")\n",
    "\n",
    "def get_llm_answer(user_prompt):\n",
    "    \n",
    "    result = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt  \n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return (result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad223bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_operator_text(label):\n",
    "    return label.split(\"TEXT:\")[1].strip()\n",
    "\n",
    "def build_CoT_prompt(row):\n",
    "    return f\"\"\"\n",
    "You are given an emergency call transcript.\n",
    "\n",
    "Previous context:\n",
    "{row['prepared_context']}\n",
    "\n",
    "Current alertant description:\n",
    "{row['prepared_samples']}\n",
    "\n",
    "Extracted keywords:\n",
    "{row['prepared_keywords']}\n",
    "\n",
    "Instructions:\n",
    "- Identify the type of incident described.\n",
    "- Determine what critical information is missing.\n",
    "- Formulate the most relevant operational question an emergency operator should ask next.\n",
    "- The question must be generic and reusable.\n",
    "- The final output must be a single question in natural Spanish.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2cc775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_operator_text\"] = df[\"prepared_labels\"].progress_apply(extract_operator_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3c93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"llm_generated_question\"] = df.progress_apply(\n",
    "    lambda row: get_llm_answer(build_CoT_prompt(row)),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80c8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrieve_top3_questions(llm_question):\n",
    "#     retrieved = retrieve_real_questions(llm_question)\n",
    "#     top3 = retrieved[:3]\n",
    "    \n",
    "#     texts = [q for _, q in top3]\n",
    "#     scores = [score for score, _ in top3]\n",
    "    \n",
    "#     return texts, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"retrieved_questions\", \"retrieved_scores\"]] = df.progress_apply(\n",
    "    lambda row: pd.Series(retrieve_real_questions(row[\"llm_generated_question\"])),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5912744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity_top3(label_text, retrieved_questions):\n",
    "    texts = [label_text] + retrieved_questions\n",
    "    # se debe formatear para este modelo, el E5 large\n",
    "    formatted = [\"query: \" + t for t in texts]\n",
    "    embeddings = model.encode(\n",
    "        formatted,\n",
    "        normalize_embeddings=True\n",
    "    )\n",
    "    \n",
    "    similarities = model.similarity(\n",
    "        embeddings[0:1],\n",
    "        embeddings[1:]\n",
    "    )\n",
    "\n",
    "    return similarities[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b69b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"semantic_sim_top_vs_label\"] = df.progress_apply(\n",
    "    lambda row: semantic_similarity_top3(\n",
    "        row[\"label_operator_text\"],\n",
    "        row[\"retrieved_questions\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394cc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"best_hit_similarity\"] = df[\"semantic_sim_top_vs_label\"].progress_apply(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba0e1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\n",
    "    \"results/experiment_v1_llm_retrieval.xlsx\",\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
